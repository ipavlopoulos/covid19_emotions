{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from time import time\n",
    "\n",
    "from torch.nn import Module\n",
    "import torch\n",
    "from torch.nn.functional import relu\n",
    "from torch import tanh\n",
    "\n",
    "from torch.nn import Module, Embedding, GRU, LSTM, Linear, ModuleList, Dropout, Dropout2d, Conv1d, MaxPool1d\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.metrics import classification_report as sklearn_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='SemEval2018-Task1-all-data/SemEval2018-Task1-all-data/English/E-c/2018-E-c-En-train.txt'\n",
    "test_path='SemEval2018-Task1-all-data/SemEval2018-Task1-all-data/English/E-c/2018-E-c-En-dev.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_path, sep='\\t')\n",
    "test_df = pd.read_csv(test_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_PATH = \"glove.twitter.27B/glove.twitter.27B.200d.txt\"\n",
    "BATCH_SIZE = 64\n",
    "UNK_TOKEN = \"$%UNK%$\"\n",
    "PAD_TOKEN = \"$%PAD%$\"\n",
    "T_LIST = ['anger', 'anticipation', 'disgust', 'fear', 'joy', \n",
    "          'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']\n",
    "i2t = {i:t for i,t in enumerate(T_LIST)}\n",
    "t2i = {t:i for i,t in enumerate(T_LIST)}\n",
    "\n",
    "EPOCHS = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "\n",
    "def tokenize(tweet):\n",
    "    return tweet_tokenizer.tokenize(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['tokens'] = train_df['Tweet'].map(lambda x: tokenize(x))\n",
    "test_df['tokens'] = test_df['Tweet'].map(lambda x: tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['lengths'] = train_df['tokens'].map(lambda x: len(x))\n",
    "test_df['lengths'] = test_df['tokens'].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(path=GLOVE_PATH):\n",
    "    embeddings_dict = {}\n",
    "    with open(path,'r', encoding='utf8') as f:\n",
    "        for line in tqdm(f):\n",
    "                values = line.strip().split(\" \")\n",
    "#                 if values[0] in tokens:\n",
    "                coefs = np.asarray(values[1:], dtype='float32')\n",
    "                embeddings_dict[values[0]] = coefs\n",
    "    return embeddings_dict\n",
    "\n",
    "def create_freq_vocabulary(tokenized_texts):\n",
    "    token_dict = {}\n",
    "    for text in tokenized_texts:\n",
    "        for token in text:\n",
    "            try:\n",
    "                token_dict[token] += 1\n",
    "            except KeyError:\n",
    "                token_dict[token] = 1\n",
    "    return token_dict\n",
    "\n",
    "\n",
    "def get_top_freq_words(token_dict, min_freq):\n",
    "    return [x for x in token_dict if token_dict[x] >= min_freq]\n",
    "\n",
    "\n",
    "def get_unique_tokens(tokenized_texts, min_freq):\n",
    "    voc = create_freq_vocabulary(tokenized_texts)\n",
    "    print(\"tokens found in training data set:\", len(voc))\n",
    "    freq_words = get_top_freq_words(voc, min_freq)\n",
    "    print(\"tokens with frequency >= %d: %d\" % (min_freq, len(freq_words)))\n",
    "    return freq_words\n",
    "\n",
    "\n",
    "def create_final_dictionary(freq_words, embeddings_dict, unk_token, pad_token):\n",
    "    words = list(set(freq_words).intersection(embeddings_dict.keys()))\n",
    "    print(\"embedded tokens: %d\" % (len(words)))\n",
    "    words = [pad_token, unk_token] + words\n",
    "    return {w: i for i, w in enumerate(words)}\n",
    "\n",
    "\n",
    "def get_embeddings_matrix(word_dict, embeddings_dict, size):\n",
    "    embs = np.zeros(shape=(len(word_dict), size))\n",
    "    for word in tqdm(word_dict):\n",
    "        try:\n",
    "            embs[word_dict[word]] = embeddings_dict[word]\n",
    "        except KeyError:\n",
    "            print('no embedding for: ', word)\n",
    "    embs[1] = np.mean(embs[2:])\n",
    "    return embs\n",
    "\n",
    "\n",
    "def get_indexed_value(w2i, word, unk_token):\n",
    "    try:\n",
    "        return w2i[word]\n",
    "    except KeyError:\n",
    "        return w2i[unk_token]\n",
    "\n",
    "\n",
    "def get_indexed_text(w2i, words, unk_token):\n",
    "    return [get_indexed_value(w2i, word, unk_token) for word in words]\n",
    "\n",
    "\n",
    "def pad_text(tokenized_text, maxlen, pad_tkn):\n",
    "    if len(tokenized_text) < maxlen:\n",
    "        return [pad_tkn] * (maxlen - len(tokenized_text)) + tokenized_text\n",
    "    else:\n",
    "        return tokenized_text[len(tokenized_text) - maxlen:]\n",
    "\n",
    "def create_batches(df, batch_size):\n",
    "    batches = []\n",
    "    offset = 0\n",
    "    while offset < len(df):\n",
    "        upper_limit = min(len(df), offset+batch_size)\n",
    "        batch_df  = df.iloc[offset: upper_limit]\n",
    "        maxlen = batch_df['lengths'].values[-1]\n",
    "            \n",
    "        batch_df['x'] = batch_df['tokens'].map(lambda x:get_indexed_text(w2i, pad_text(x, maxlen, PAD_TOKEN),UNK_TOKEN))\n",
    "        batches.append({'x':np.array([x for x in batch_df['x']], dtype=np.int32), \n",
    "                        'y': np.array(batch_df[T_LIST], dtype=np.float32)})\n",
    "#         print(np.array([x for x in batch_df['x']], dtype=np.int32))\n",
    "        offset = upper_limit\n",
    "    return batches        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_dict = create_freq_vocabulary(list(train_df['tokens']) + list(test_df['tokens']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = get_top_freq_words(word_freq_dict, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.sort_values(by=\"lengths\")\n",
    "test_df = test_df.sort_values(by=\"lengths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16100"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1193514it [01:24, 14070.42it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings = get_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11080/11080 [00:00<00:00, 241554.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded tokens: 11078\n",
      "no embedding for:  $%PAD%$\n",
      "no embedding for:  $%UNK%$\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "w2i = create_final_dictionary(tokens, embeddings, unk_token=UNK_TOKEN, pad_token=PAD_TOKEN)\n",
    "emb_matrix = get_embeddings_matrix(w2i, embeddings, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SpatialDropout(Dropout2d):\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(2)    # (N, T, 1, K)\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n",
    "        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n",
    "        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n",
    "        x = x.squeeze(2)  # (N, T, K)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Layer(Module):\n",
    "    def __init__(self):\n",
    "        super(Layer, self).__init__()\n",
    "\n",
    "    def get_output_size(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_input_size(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class PretrainedEmbeddingLayer(Layer):\n",
    "    def __init__(self, embeddings, dropout=0.0, trainable=True):\n",
    "        \"\"\"\n",
    "        :param embeddings: a numpy array with the embeddings\n",
    "        :param trainable: if false the embeddings will be frozen\n",
    "        \"\"\"\n",
    "        super(PretrainedEmbeddingLayer, self).__init__()\n",
    "        self.__input_size = embeddings.shape[0]\n",
    "        self.__output_size = embeddings.shape[1]\n",
    "        self.dropout = SpatialDropout(dropout)\n",
    "        self.embed = Embedding(embeddings.shape[0], embeddings.shape[1])\n",
    "        self.embed.weight.data.copy_(torch.from_numpy(embeddings))\n",
    "        if not trainable:\n",
    "            self.embed.weight.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dropout(self.embed(x))\n",
    "\n",
    "    def get_output_size(self):\n",
    "        return self.__output_size\n",
    "\n",
    "    def get_input_size(self):\n",
    "        return self.__input_size\n",
    "\n",
    "class ConvBlock(Layer):\n",
    "    def __init__(self,in_channels, filters, window=2, dropout=0.0, trainable=True):\n",
    "        \"\"\"\n",
    "        :param embeddings: a numpy array with the embeddings\n",
    "        :param trainable: if false the embeddings will be frozen\n",
    "        \"\"\"\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.__input_size =  in_channels\n",
    "        self.__output_size = filters\n",
    "        self.conv = Conv1d(in_channels=in_channels, out_channels=filters, kernel_size=window, padding=(window // 2))\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.max(self.conv(x.permute(0,2,1)), 2)[0]\n",
    "\n",
    "    def get_output_size(self):\n",
    "        return self.__output_size\n",
    "\n",
    "    def get_input_size(self):\n",
    "        return self.__input_size\n",
    "\n",
    "class CellLayer(Layer):\n",
    "    def __init__(self, is_gru, input_size,  hidden_size, bidirectional, stacked_layers):\n",
    "        \"\"\"\n",
    "        :param is_gru: GRU cell type if true, otherwise LSTM\n",
    "        :param input_size: the size of the tensors that will be used as input (embeddings or projected embeddings)\n",
    "        :param hidden_size: the size of the cell\n",
    "        :param bidirectional: boolean\n",
    "        :param stacked_layers: the number of stacked layers\n",
    "        \"\"\"\n",
    "        super(CellLayer, self).__init__()\n",
    "        if is_gru:\n",
    "            self.cell = GRU(input_size=input_size, hidden_size=hidden_size, batch_first=True,\n",
    "                            bidirectional=bidirectional, num_layers=stacked_layers)\n",
    "\n",
    "        else:\n",
    "            self.cell = LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True,\n",
    "                             bidirectional=bidirectional, num_layers=stacked_layers)\n",
    "\n",
    "        self.__output_size = hidden_size * 2 if bidirectional else hidden_size\n",
    "        self.__input_size = input_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cell(x)[0]\n",
    "\n",
    "    def get_output_size(self):\n",
    "        return self.__output_size\n",
    "\n",
    "    def get_input_size(self):\n",
    "        return self.__input_size\n",
    "\n",
    "\n",
    "class MLP(Layer):\n",
    "    def __init__(self, num_of_layers, init_size, out_size, dropout=0.0, inner_activation=None, outer_activation=None):\n",
    "        \"\"\"\n",
    "        :param num_of_layers: the total number of layers\n",
    "        :param init_size: unit size of hidden layers\n",
    "        :param out_size: output size\n",
    "        :param inner_activation: the activation function for the inner layers\n",
    "        :param outer_activation: the activation function for the last layer\n",
    "        \"\"\"\n",
    "        super(MLP, self).__init__()\n",
    "        self.num_of_layers = num_of_layers\n",
    "        self.__input_size = init_size\n",
    "        self.__output_size = out_size\n",
    "        self.dropout = Dropout(dropout)\n",
    "        if self.num_of_layers > 0:\n",
    "            self.layers = ModuleList([Linear(init_size, init_size) for _ in range(num_of_layers-1)] + [Linear(init_size, out_size)])\n",
    "            self.activation_list = [inner_activation for _ in range(num_of_layers - 1)] + [outer_activation]\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.num_of_layers > 0:\n",
    "            for layer, activation in zip(self.layers, self.activation_list):\n",
    "                if activation is None:\n",
    "                    x = self.dropout(layer(x))\n",
    "                else:\n",
    "                    x = self.dropout(activation(layer(x)))\n",
    "        return x\n",
    "\n",
    "    def get_output_size(self):\n",
    "        return self.__output_size\n",
    "\n",
    "    def get_input_size(self):\n",
    "        return self.__input_size\n",
    "\n",
    "\n",
    "class LastState(Layer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LastState, self).__init__()\n",
    "        self.__input_size = input_size\n",
    "        self.__output_size = output_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, -1, :]\n",
    "\n",
    "    def get_input_size(self):\n",
    "        return self.__input_size\n",
    "\n",
    "    def get_output_size(self):\n",
    "        return self.__output_size\n",
    "\n",
    "class AttendedState(Layer):\n",
    "    def __init__(self, num_of_layers, hidden_size, dropout=0.0, activation=None):\n",
    "        super(AttendedState, self).__init__()\n",
    "        self.__input_size = hidden_size\n",
    "        self.__output_size = hidden_size\n",
    "        self.mlp = MLP(num_of_layers=num_of_layers,\n",
    "                       init_size=hidden_size, out_size=hidden_size,\n",
    "                       dropout=dropout,\n",
    "                       inner_activation=activation,\n",
    "                       outer_activation=activation)\n",
    "\n",
    "        self.attention = Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        states_mlp = self.mlp(x)\n",
    "        att_sc_dist = self.attention(states_mlp).squeeze(-1)\n",
    "        att_weights = softmax(att_sc_dist, dim=1).unsqueeze(2)\n",
    "        out_attended = torch.sum(torch.mul(att_weights, x), dim=1)\n",
    "        return out_attended\n",
    "\n",
    "    def get_input_size(self):\n",
    "        return self.__input_size\n",
    "\n",
    "    def get_output_size(self):\n",
    "        return self.__output_size\n",
    "\n",
    "    \n",
    "class AvgPoolingState(Layer):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(AvgPoolingState, self).__init__()\n",
    "        self.__input_size = input_size\n",
    "        self.__output_size = output_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.mean(x, 1)\n",
    "\n",
    "    def get_input_size(self):\n",
    "        return self.__input_size\n",
    "\n",
    "    def get_output_size(self):\n",
    "        return self.__output_size\n",
    "    \n",
    "class ConcatenationLayer(Layer):\n",
    "    def __init__(self, layer1, layer2):\n",
    "        super(ConcatenationLayer, self).__init__()\n",
    "        self.__input_size = layer1.get_input_size() + layer2.get_input_size()\n",
    "        self.__output_size = self.__input_size\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return torch.cat((x, y), 1)\n",
    "\n",
    "    def get_input_size(self):\n",
    "        return self.__input_size\n",
    "\n",
    "    def get_output_size(self):\n",
    "        return self.__output_size\n",
    "\n",
    "\n",
    "class SequentialModel(Layer):\n",
    "    def __init__(self, layers):\n",
    "        super(Layer, self).__init__()\n",
    "        for i in range(len(layers)-1):\n",
    "            assert (layers[i].get_output_size() == layers[i+1].get_input_size())\n",
    "        self.layers = ModuleList(layers)\n",
    "        self.__output_size = self.layers[-1].get_output_size()\n",
    "        self.__input_size = self.layers[0].get_input_size()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def get_input_size(self):\n",
    "        return self.__input_size\n",
    "\n",
    "    def get_output_size(self):\n",
    "        return self.__output_size\n",
    "\n",
    "    def add_layer(self, layer):\n",
    "        assert (layer.get_input_size() == self.__input_size)\n",
    "        self.layers.append(layer)\n",
    "        self.__output_size = layer.get_output_size()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProjectedMultiAttentionRNN(Module):\n",
    "    def __init__(self, embeddings,\n",
    "                 embeddings_dropout=0.0,\n",
    "                 is_gru=True,\n",
    "                 cell_hidden_size=128,\n",
    "                 stacked_layers=1,\n",
    "                 bidirectional=False,\n",
    "                 att_mlp_layers=1,\n",
    "                 att_mlp_dropout=0.0,\n",
    "                 top_mlp_layers=2,\n",
    "                 top_mlp_activation=relu,\n",
    "                 top_mlp_outer_activation=None, targets=11,\n",
    "                 top_mlp_dropout=0.0):\n",
    "\n",
    "        super(ProjectedMultiAttentionRNN, self).__init__()\n",
    "        self.name = \"ProjectedMultiAttentionRNN\"\n",
    "\n",
    "        self.word_embedding_layer = PretrainedEmbeddingLayer(embeddings, dropout=embeddings_dropout, trainable=False)\n",
    "        self.projection_layer = MLP(num_of_layers=1, init_size=self.word_embedding_layer.get_output_size(),\n",
    "                                        out_size=128, outer_activation=tanh)\n",
    "        self.cell = CellLayer(is_gru, self.projection_layer.get_output_size(),\n",
    "                              cell_hidden_size, bidirectional, stacked_layers)\n",
    "        large_size = cell_hidden_size * 2 if bidirectional else cell_hidden_size\n",
    "        decision_layers = [MLP(num_of_layers=top_mlp_layers,\n",
    "                                           init_size=large_size,\n",
    "                                           out_size=1,\n",
    "                                           dropout=top_mlp_dropout,\n",
    "                                           inner_activation=top_mlp_activation,\n",
    "                                           outer_activation=top_mlp_outer_activation) for _ in range(targets)]\n",
    "        self.decision_layers = ModuleList(decision_layers)\n",
    "        self.attentions = ModuleList([AttendedState(att_mlp_layers, large_size, att_mlp_dropout, relu) for _ in range(targets)])\n",
    "        self.seq = SequentialModel([self.word_embedding_layer, self.projection_layer, self.cell])\n",
    "        self.params = list(filter(lambda p: p.requires_grad, self.parameters()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder = self.seq(x)\n",
    "        states = [desicion(attention(encoder)) for attention, desicion in zip(self.attentions, self.decision_layers)]\n",
    "        out = torch.cat(states, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(Module):\n",
    "    def __init__(self, embeddings,\n",
    "                 embeddings_dropout=0.0,\n",
    "                 filters=32,              \n",
    "                 top_mlp_layers=2,\n",
    "                 top_mlp_activation=relu,\n",
    "                 top_mlp_outer_activation=None, targets=11,\n",
    "                 top_mlp_dropout=0.0):\n",
    "\n",
    "        super(CNN, self).__init__()\n",
    "        self.name = \"CNN\"\n",
    "\n",
    "        self.word_embedding_layer = PretrainedEmbeddingLayer(embeddings, dropout=embeddings_dropout, trainable=False)\n",
    "        \n",
    "        conv_blocks = [ConvBlock(in_channels= self.word_embedding_layer.get_output_size(), \n",
    "                            filters=filters, window=i) for i in range(2,6)]\n",
    "        \n",
    "        self.conv_blocks = ModuleList(conv_blocks)\n",
    "        \n",
    "        large_size = len(conv_blocks) * filters\n",
    "        decision_layers = [MLP(num_of_layers=top_mlp_layers,\n",
    "                                           init_size=large_size,\n",
    "                                           out_size=1,\n",
    "                                           dropout=top_mlp_dropout,\n",
    "                                           inner_activation=top_mlp_activation,\n",
    "                                           outer_activation=top_mlp_outer_activation) for _ in range(targets)]\n",
    "        self.decision_layers = ModuleList(decision_layers)\n",
    "        \n",
    "        self.params = list(filter(lambda p: p.requires_grad, self.parameters()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        embs = self.word_embedding_layer(x)\n",
    "        convs = [block(embs) for block in self.conv_blocks]\n",
    "        encoder = torch.cat(convs, dim=1)\n",
    "        states = [desicion(encoder) for desicion in self.decision_layers]\n",
    "        out = torch.cat(states, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAttentionRNN(Module):\n",
    "    def __init__(self, embeddings,\n",
    "                 embeddings_dropout=0.0,\n",
    "                 is_gru=True,\n",
    "                 cell_hidden_size=128,\n",
    "                 stacked_layers=1,\n",
    "                 bidirectional=False,\n",
    "                 att_mlp_layers=1,\n",
    "                 att_mlp_dropout=0.0,\n",
    "                 top_mlp_layers=2,\n",
    "                 top_mlp_activation=relu,\n",
    "                 top_mlp_outer_activation=None, targets=11,\n",
    "                 top_mlp_dropout=0.0):\n",
    "\n",
    "        super(MultiAttentionRNN, self).__init__()\n",
    "        self.name = \"MultiAttentionRNN\"\n",
    "\n",
    "        self.word_embedding_layer = PretrainedEmbeddingLayer(embeddings, dropout=embeddings_dropout, trainable=False)\n",
    "    \n",
    "        self.cell = CellLayer(is_gru, self.word_embedding_layer.get_output_size(),\n",
    "                              cell_hidden_size, bidirectional, stacked_layers)\n",
    "        large_size = cell_hidden_size * 2 if bidirectional else cell_hidden_size\n",
    "        decision_layers = [MLP(num_of_layers=top_mlp_layers,\n",
    "                                           init_size=large_size,\n",
    "                                           out_size=1,\n",
    "                                           dropout=top_mlp_dropout,\n",
    "                                           inner_activation=top_mlp_activation,\n",
    "                                           outer_activation=top_mlp_outer_activation) for _ in range(targets)]\n",
    "        self.decision_layers = ModuleList(decision_layers)\n",
    "        self.attentions = ModuleList([AttendedState(att_mlp_layers, large_size, att_mlp_dropout, relu) for _ in range(targets)])\n",
    "        self.seq = SequentialModel([self.word_embedding_layer, self.cell])\n",
    "        self.params = list(filter(lambda p: p.requires_grad, self.parameters()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder = self.seq(x)\n",
    "        states = [desicion(attention(encoder)) for attention, desicion in zip(self.attentions, self.decision_layers)]\n",
    "        out = torch.cat(states, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAttentionRNNConcatCNN(Module):\n",
    "    def __init__(self, embeddings,\n",
    "                 embeddings_dropout=0.0,\n",
    "                 is_gru=True,\n",
    "                 filters=32,\n",
    "                 cell_hidden_size=128,\n",
    "                 stacked_layers=1,\n",
    "                 bidirectional=False,\n",
    "                 att_mlp_layers=1,\n",
    "                 att_mlp_dropout=0.0,\n",
    "                 top_mlp_layers=2,\n",
    "                 top_mlp_activation=relu,\n",
    "                 top_mlp_outer_activation=None, targets=11,\n",
    "                 top_mlp_dropout=0.0):\n",
    "\n",
    "        super(MultiAttentionRNNConcatCNN, self).__init__()\n",
    "        self.name = \"MultiAttentionRNNConcatCNN\"\n",
    "        self.targets = targets\n",
    "\n",
    "        self.word_embedding_layer = PretrainedEmbeddingLayer(embeddings, dropout=embeddings_dropout, trainable=False)\n",
    "        conv_blocks = [ConvBlock(in_channels= self.word_embedding_layer.get_output_size(), \n",
    "                            filters=filters, window=i) for i in range(2,6)]\n",
    "        self.conv_blocks = ModuleList(conv_blocks)\n",
    "        self.cell = CellLayer(is_gru, self.word_embedding_layer.get_output_size(),\n",
    "                              cell_hidden_size, bidirectional, stacked_layers)\n",
    "        large_size = cell_hidden_size * 2 if bidirectional else cell_hidden_size\n",
    "        large_size_top = large_size + filters * len(conv_blocks)\n",
    "        decision_layers = [MLP(num_of_layers=top_mlp_layers,\n",
    "                                           init_size=large_size_top,\n",
    "                                           out_size=1,\n",
    "                                           dropout=top_mlp_dropout,\n",
    "                                           inner_activation=top_mlp_activation,\n",
    "                                           outer_activation=top_mlp_outer_activation) for _ in range(targets)]\n",
    "        self.decision_layers = ModuleList(decision_layers)\n",
    "        attentions = [AttendedState(att_mlp_layers, large_size, att_mlp_dropout, relu) for _ in range(targets)]\n",
    "        self.attentions = ModuleList(attentions)\n",
    "        self.params = list(filter(lambda p: p.requires_grad, self.parameters()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        embs = self.word_embedding_layer(x)\n",
    "        convs = [block(embs) for block in self.conv_blocks]\n",
    "        encoder1 = torch.cat(convs, dim=1)\n",
    "        \n",
    "        encoder2 = self.cell(embs)\n",
    "        states = [attention(encoder2) for attention in self.attentions]\n",
    "        states = [torch.cat((state, encoder1), dim=1) for state in states]\n",
    "        decisions = [decision(state) for decision, state in zip(self.decision_layers, states)]\n",
    "        out = torch.cat(decisions, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastStateRNN(Module):\n",
    "    def __init__(self, embeddings,\n",
    "                 embeddings_dropout=0.0,\n",
    "                 is_gru=True,\n",
    "                 cell_hidden_size=128,\n",
    "                 stacked_layers=1,\n",
    "                 bidirectional=False,\n",
    "                 att_mlp_layers=1,\n",
    "                 att_mlp_dropout=0.0,\n",
    "                 top_mlp_layers=2,\n",
    "                 top_mlp_activation=relu,\n",
    "                 top_mlp_outer_activation=None, targets=11,\n",
    "                 top_mlp_dropout=0.0):\n",
    "\n",
    "        super(LastStateRNN, self).__init__()\n",
    "        self.name = \"LastStateRNN\"\n",
    "\n",
    "        self.word_embedding_layer = PretrainedEmbeddingLayer(embeddings, dropout=embeddings_dropout, trainable=False)\n",
    "    \n",
    "        self.cell = CellLayer(is_gru, self.word_embedding_layer.get_output_size(),\n",
    "                              cell_hidden_size, bidirectional, stacked_layers)\n",
    "        large_size = cell_hidden_size * 2 if bidirectional else cell_hidden_size\n",
    "        decision_layers = [MLP(num_of_layers=top_mlp_layers,\n",
    "                                           init_size=large_size,\n",
    "                                           out_size=1,\n",
    "                                           dropout=top_mlp_dropout,\n",
    "                                           inner_activation=top_mlp_activation,\n",
    "                                           outer_activation=top_mlp_outer_activation) for _ in range(targets)]\n",
    "        self.decision_layers = ModuleList(decision_layers)\n",
    "        self.attentions = ModuleList([LastState(large_size, large_size) for _ in range(targets)])\n",
    "        self.seq = SequentialModel([self.word_embedding_layer, self.cell])\n",
    "        self.params = list(filter(lambda p: p.requires_grad, self.parameters()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder = self.seq(x)\n",
    "        states = [desicion(attention(encoder)) for attention, desicion in zip(self.attentions, self.decision_layers)]\n",
    "        out = torch.cat(states, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPWithAttentionModel(Module):\n",
    "    def __init__(self, embeddings,\n",
    "                 embeddings_dropout=0.0,\n",
    "                 att_mlp_layers=1,\n",
    "                 att_mlp_dropout=0.0,\n",
    "                 top_mlp_layers=3,\n",
    "                 top_mlp_activation=relu,\n",
    "                 top_mlp_outer_activation=None, targets=11,\n",
    "                 top_mlp_dropout=0.0):\n",
    "\n",
    "        super(MLPWithAttentionModel, self).__init__()\n",
    "        self.name = \"MLPWithAttentionModel\"\n",
    "\n",
    "        self.word_embedding_layer = PretrainedEmbeddingLayer(embeddings, dropout=embeddings_dropout, trainable=False)\n",
    "        self.projection_layer = MLP(num_of_layers=1, init_size=self.word_embedding_layer.get_output_size(),\n",
    "                                    out_size=128, outer_activation=tanh)\n",
    "        large_size = self.projection_layer.get_output_size()\n",
    "        decision_layers = [MLP(num_of_layers=top_mlp_layers,\n",
    "                                           init_size=large_size,\n",
    "                                           out_size=1,\n",
    "                                           dropout=top_mlp_dropout,\n",
    "                                           inner_activation=top_mlp_activation,\n",
    "                                           outer_activation=top_mlp_outer_activation) for _ in range(targets)]\n",
    "        self.decision_layers = ModuleList(decision_layers)\n",
    "        attentions = [AttendedState(att_mlp_layers, large_size, att_mlp_dropout, relu) for _ in range(targets)]\n",
    "        self.attentions = ModuleList(attentions)\n",
    "        self.seq = SequentialModel([self.word_embedding_layer, self.projection_layer])\n",
    "        \n",
    "        self.params = list(filter(lambda p: p.requires_grad, self.parameters()))\n",
    "\n",
    "    def forward(self,x):\n",
    "        encoder = self.seq(x)\n",
    "        states = [desicion(attention(encoder)) for attention, desicion in zip(self.attentions, self.decision_layers)]\n",
    "        out = torch.cat(states, dim=1)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "class MLPModel(Module):\n",
    "    def __init__(self, embeddings,\n",
    "                 embeddings_dropout=0.0,\n",
    "                 att_mlp_layers=1,\n",
    "                 att_mlp_dropout=0.0,\n",
    "                 top_mlp_layers=3,\n",
    "                 top_mlp_activation=relu,\n",
    "                 top_mlp_outer_activation=None, targets=11,\n",
    "                 top_mlp_dropout=0.0):\n",
    "\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.name = \"MLPModel\"\n",
    "\n",
    "        self.word_embedding_layer = PretrainedEmbeddingLayer(embeddings, dropout=embeddings_dropout, trainable=False)\n",
    "        large_size = self.word_embedding_layer.get_output_size()\n",
    "        decision_layers = [MLP(num_of_layers=top_mlp_layers,\n",
    "                                           init_size=large_size,\n",
    "                                           out_size=1,\n",
    "                                           dropout=top_mlp_dropout,\n",
    "                                           inner_activation=top_mlp_activation,\n",
    "                                           outer_activation=top_mlp_outer_activation) for _ in range(targets)]\n",
    "        self.decision_layers = ModuleList(decision_layers)\n",
    "        attentions = [AvgPoolingState(input_size=large_size, output_size=large_size) for _ in range(targets)]\n",
    "        self.attentions = ModuleList(attentions)\n",
    "        \n",
    "        self.params = list(filter(lambda p: p.requires_grad, self.parameters()))\n",
    "\n",
    "    def forward(self,x):\n",
    "        encoder = self.word_embedding_layer(x)\n",
    "        states = [desicion(attention(encoder)) for attention, desicion in zip(self.attentions, self.decision_layers)]\n",
    "        out = torch.cat(states, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleAttentionRNN(Module):\n",
    "    def __init__(self, embeddings,\n",
    "                 embeddings_dropout=0.0,\n",
    "                 is_gru=True,\n",
    "                 cell_hidden_size=128,\n",
    "                 stacked_layers=1,\n",
    "                 bidirectional=False,\n",
    "                 att_mlp_layers=2,\n",
    "                 att_mlp_dropout=0.0,\n",
    "                 top_mlp_layers=1,\n",
    "                 top_mlp_activation=relu,\n",
    "                 top_mlp_outer_activation=None, targets=11,\n",
    "                 top_mlp_dropout=0.0):\n",
    "\n",
    "        super(SingleAttentionRNN, self).__init__()\n",
    "        self.name = \"SingleAttentionRNN\"\n",
    "\n",
    "        self.word_embedding_layer = PretrainedEmbeddingLayer(embeddings, dropout=embeddings_dropout, trainable=False)\n",
    "    \n",
    "        self.cell = CellLayer(is_gru, self.word_embedding_layer.get_output_size(),\n",
    "                              cell_hidden_size, bidirectional, stacked_layers)\n",
    "        large_size = cell_hidden_size * 2 if bidirectional else cell_hidden_size\n",
    "        self.decision_layer = MLP(num_of_layers=top_mlp_layers,\n",
    "                                           init_size=large_size,\n",
    "                                           out_size=targets,\n",
    "                                           dropout=top_mlp_dropout,\n",
    "                                           inner_activation=top_mlp_activation,\n",
    "                                           outer_activation=top_mlp_outer_activation)\n",
    "        self.attention = AttendedState(att_mlp_layers, large_size, att_mlp_dropout, relu)\n",
    "        self.seq = SequentialModel([self.word_embedding_layer, self.cell])\n",
    "        self.params = list(filter(lambda p: p.requires_grad, self.parameters()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder = self.seq(x)\n",
    "        out = self.decision_layer(self.attention(encoder))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_DIR = \"\"\n",
    "def save_model(model):\n",
    "    torch.save(model.state_dict(), MODELS_DIR + model.name + '.pkl')\n",
    "\n",
    "\n",
    "def load_model(model):\n",
    "    model.load_state_dict(torch.load(MODELS_DIR + model.name + '.pkl'))\n",
    "    return model\n",
    "\n",
    "def train(model, train_batches, test_batches, optimizer,  criterion,\n",
    "                          epochs, init_patience, cuda=True):\n",
    "    patience = init_patience\n",
    "    best_auc = 0.0\n",
    "    for i in range(1, epochs + 1):\n",
    "        start = time()\n",
    "        auc = run_epoch(model, train_batches, test_batches, optimizer,  criterion,\n",
    "                                         cuda)\n",
    "        end = time()\n",
    "        print('epoch %d, auc: %2.3f  Time: %d minutes, %d seconds'\n",
    "              % (i, 100 * auc, (end - start) / 60, (end - start) % 60))\n",
    "        if best_auc < auc:\n",
    "            best_auc = auc\n",
    "            patience = init_patience\n",
    "            save_model(model)\n",
    "            if i > 1:\n",
    "                print('best epoch so far')\n",
    "        else:\n",
    "            patience -= 1\n",
    "        if patience == 0:\n",
    "            break\n",
    "    return best_auc\n",
    "\n",
    "\n",
    "def run_epoch(model, train_batches, test_batches, optimizer, criterion, cuda):\n",
    "    model.train(True)\n",
    "    perm = np.random.permutation(len(train_batches))\n",
    "    for i in tqdm(perm):\n",
    "        batch = train_batches[i]\n",
    "        inner_perm = np.random.permutation(len(batch['x']))\n",
    "        data = []\n",
    "        if cuda:\n",
    "            data.append(Variable(torch.from_numpy(batch['x'][inner_perm]).long().cuda()))\n",
    "        else:\n",
    "            data.append(Variable(torch.from_numpy(batch['x'][inner_perm]).long()))\n",
    "        if cuda:\n",
    "            y = Variable(torch.from_numpy(batch['y'][inner_perm]).cuda())\n",
    "        else:\n",
    "            y = Variable(torch.from_numpy(batch['y'][inner_perm]))\n",
    "        outputs = model(*data)\n",
    "        loss = criterion(outputs, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return evaluate(model, test_batches, T_LIST)\n",
    "    \n",
    "\n",
    "\n",
    "def evaluate(model, test_batches, y_list):\n",
    "    model.train(False)\n",
    "    results = get_scores(model, test_batches, y_list)\n",
    "    auc_scores = []\n",
    "    for k in results:\n",
    "        auc = roc_auc_score(results[k]['labels'],np.asarray(results[k]['scores'],  dtype='float32'))\n",
    "#         print(\"{} - auc:{}\".format(y_list[k], auc))\n",
    "        auc_scores.append(auc)\n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "def get_scores(model, test_batches, y_list):\n",
    "    results = {y:{'scores':[], 'labels':[]}  for y in range(len(y_list))}\n",
    "    for batch in test_batches:\n",
    "        batch_scores = model(torch.from_numpy(batch['x']).long())\n",
    "        for i in range(len(y_list)):\n",
    "            results[i]['scores'].extend(batch_scores[:,i].detach().numpy())\n",
    "            results[i]['labels'].extend(batch['y'][:,i])\n",
    "    return results\n",
    "\n",
    "def best_thr(labels, scores):\n",
    "    thr = 0.05\n",
    "    best_thr = 0.05\n",
    "    best_f1 = 0.0\n",
    "    for thr in np.arange(0.01, 0.99, 0.01):\n",
    "        scr = f1_score(labels, [x > thr for x in scores])\n",
    "        if scr > best_f1:\n",
    "            best_f1 = scr\n",
    "            best_thr = thr\n",
    "    return best_thr\n",
    "\n",
    "\n",
    "def classification_report(model, test_batches, y_list):\n",
    "    model.train(False)\n",
    "    results = get_scores(model, test_batches, y_list)\n",
    "    print(\"\\tEmotion\\tAUC\\tAccuracy \")\n",
    "    best_thresholds = {}\n",
    "    for k,emotion in enumerate(y_list):\n",
    "        best_thresholds[emotion] = best_thr(results[k]['labels'],np.asarray(results[k]['scores']))\n",
    "        auc = roc_auc_score(results[k]['labels'],np.asarray(results[k]['scores'],  dtype='float32'))\n",
    "       \n",
    "        acc = accuracy_score(results[k]['labels'],np.asarray([x>best_thresholds[emotion] for x in results[k]['scores']],  dtype='float32'))\n",
    "        print (\"\\t{:.5s}\\t{:.4f}\\t{:.4f}\".format(emotion, auc, acc))\n",
    "    full_predictions = np.zeros(shape=(len(results[0]['scores']), len(y_list)))\n",
    "    full_targets = np.zeros(shape=(len(results[0]['scores']), len(y_list)))\n",
    "    for i in range(len(y_list)):\n",
    "        full_predictions[:,i] = [x>best_thresholds[y_list[i]] for x in results[i]['scores']]\n",
    "        full_targets[:,i] = results[i]['labels']\n",
    "    print(sklearn_cr(full_targets, full_predictions, target_names=y_list))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giannis/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "train_batches = create_batches(train_df, BATCH_SIZE)\n",
    "test_batches = create_batches(test_df, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP over the Average of the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 21.18it/s]\n",
      "  3%|▎         | 3/107 [00:00<00:04, 21.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, auc: 74.008  Time: 0 minutes, 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 18.59it/s]\n",
      "  3%|▎         | 3/107 [00:00<00:03, 26.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, auc: 76.241  Time: 0 minutes, 6 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:04<00:00, 25.01it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:06, 15.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, auc: 76.460  Time: 0 minutes, 4 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:04<00:00, 23.39it/s]\n",
      "  4%|▎         | 4/107 [00:00<00:02, 38.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, auc: 76.815  Time: 0 minutes, 4 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:04<00:00, 23.08it/s]\n",
      "  3%|▎         | 3/107 [00:00<00:03, 29.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, auc: 76.711  Time: 0 minutes, 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 20.48it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:07, 14.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, auc: 76.380  Time: 0 minutes, 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 19.91it/s]\n",
      "  3%|▎         | 3/107 [00:00<00:03, 29.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, auc: 75.908  Time: 0 minutes, 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:04<00:00, 24.52it/s]\n",
      "  3%|▎         | 3/107 [00:00<00:04, 25.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, auc: 75.756  Time: 0 minutes, 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 20.12it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:07, 14.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, auc: 74.485  Time: 0 minutes, 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:04<00:00, 22.39it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:06, 15.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, auc: 73.964  Time: 0 minutes, 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:04<00:00, 24.83it/s]\n",
      "  3%|▎         | 3/107 [00:00<00:03, 29.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, auc: 73.149  Time: 0 minutes, 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 21.38it/s]\n",
      "  3%|▎         | 3/107 [00:00<00:04, 24.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, auc: 73.390  Time: 0 minutes, 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:04<00:00, 26.19it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:07, 13.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, auc: 72.560  Time: 0 minutes, 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:04<00:00, 25.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, auc: 72.419  Time: 0 minutes, 4 seconds\n",
      "\tEmotion\tAUC\tAccuracy \n",
      "\tanger\t0.8160\t0.7686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giannis/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tantic\t0.6354\t0.8600\n",
      "\tdisgu\t0.8150\t0.7483\n",
      "\tfear\t0.8094\t0.8837\n",
      "\tjoy\t0.8426\t0.7517\n",
      "\tlove\t0.8456\t0.8860\n",
      "\toptim\t0.7982\t0.7664\n",
      "\tpessi\t0.7182\t0.8871\n",
      "\tsadne\t0.7486\t0.7370\n",
      "\tsurpr\t0.7139\t0.9605\n",
      "\ttrust\t0.7066\t0.9515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.67      0.68      0.68       315\n",
      "anticipation       0.00      0.00      0.00       124\n",
      "     disgust       0.65      0.66      0.65       319\n",
      "        fear       0.69      0.27      0.39       121\n",
      "         joy       0.78      0.63      0.70       400\n",
      "        love       0.71      0.39      0.51       132\n",
      "    optimism       0.70      0.57      0.63       307\n",
      "   pessimism       0.00      0.00      0.00       100\n",
      "     sadness       0.74      0.18      0.30       265\n",
      "    surprise       0.00      0.00      0.00        35\n",
      "       trust       0.00      0.00      0.00        43\n",
      "\n",
      "   micro avg       0.70      0.46      0.55      2161\n",
      "   macro avg       0.45      0.31      0.35      2161\n",
      "weighted avg       0.61      0.46      0.50      2161\n",
      " samples avg       0.59      0.47      0.49      2161\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giannis/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/giannis/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/giannis/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model = MLPModel(emb_matrix)\n",
    "optimizer = Adam(model.params, 0.001)\n",
    "criterion = BCEWithLogitsLoss()\n",
    "train(model, train_batches, test_batches, optimizer,  criterion, epochs=20, init_patience=10, cuda=False)\n",
    "model = load_model(model)\n",
    "classification_report(model, test_batches, T_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP with Attention on the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:10<00:00, 10.32it/s]\n",
      "  0%|          | 0/107 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, auc: 72.343  Time: 0 minutes, 10 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:11<00:00,  9.33it/s]\n",
      "  1%|          | 1/107 [00:00<00:12,  8.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, auc: 77.998  Time: 0 minutes, 11 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:11<00:00,  9.42it/s]\n",
      "  1%|          | 1/107 [00:00<00:12,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, auc: 79.660  Time: 0 minutes, 11 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:10<00:00, 10.32it/s]\n",
      "  0%|          | 0/107 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, auc: 79.914  Time: 0 minutes, 10 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:10<00:00,  9.97it/s]\n",
      "  0%|          | 0/107 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, auc: 80.271  Time: 0 minutes, 11 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:10<00:00,  9.91it/s]\n",
      "  1%|          | 1/107 [00:00<00:11,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, auc: 80.073  Time: 0 minutes, 11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:10<00:00, 10.53it/s]\n",
      "  1%|          | 1/107 [00:00<00:10,  9.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, auc: 80.195  Time: 0 minutes, 10 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:10<00:00, 10.06it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:08, 12.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, auc: 80.199  Time: 0 minutes, 11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:10<00:00,  9.97it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:08, 12.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, auc: 80.131  Time: 0 minutes, 11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:11<00:00,  9.37it/s]\n",
      "  0%|          | 0/107 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, auc: 79.673  Time: 0 minutes, 11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:11<00:00,  9.33it/s]\n",
      "  1%|          | 1/107 [00:00<00:10,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, auc: 79.954  Time: 0 minutes, 11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:10<00:00, 10.64it/s]\n",
      "  1%|          | 1/107 [00:00<00:12,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, auc: 79.313  Time: 0 minutes, 10 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:09<00:00, 11.80it/s]\n",
      "  0%|          | 0/107 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, auc: 79.518  Time: 0 minutes, 9 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:12<00:00,  8.87it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:09, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, auc: 78.752  Time: 0 minutes, 12 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:13<00:00,  7.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, auc: 78.385  Time: 0 minutes, 13 seconds\n",
      "\tEmotion\tAUC\tAccuracy \n",
      "\tanger\t0.8353\t0.7912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giannis/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tantic\t0.6780\t0.8600\n",
      "\tdisgu\t0.8214\t0.7528\n",
      "\tfear\t0.8626\t0.8928\n",
      "\tjoy\t0.8638\t0.7810\n",
      "\tlove\t0.8868\t0.8916\n",
      "\toptim\t0.8227\t0.7709\n",
      "\tpessi\t0.7304\t0.8883\n",
      "\tsadne\t0.7833\t0.7607\n",
      "\tsurpr\t0.8103\t0.9616\n",
      "\ttrust\t0.7352\t0.9515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.75      0.62      0.68       315\n",
      "anticipation       0.00      0.00      0.00       124\n",
      "     disgust       0.69      0.58      0.63       319\n",
      "        fear       0.65      0.46      0.54       121\n",
      "         joy       0.85      0.63      0.72       400\n",
      "        love       0.76      0.39      0.52       132\n",
      "    optimism       0.73      0.53      0.62       307\n",
      "   pessimism       0.55      0.06      0.11       100\n",
      "     sadness       0.71      0.34      0.46       265\n",
      "    surprise       1.00      0.03      0.06        35\n",
      "       trust       0.00      0.00      0.00        43\n",
      "\n",
      "   micro avg       0.75      0.46      0.57      2161\n",
      "   macro avg       0.61      0.33      0.39      2161\n",
      "weighted avg       0.68      0.46      0.54      2161\n",
      " samples avg       0.61      0.48      0.51      2161\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giannis/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/giannis/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/giannis/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "model = MLPWithAttentionModel(emb_matrix)\n",
    "optimizer = Adam(model.params, 0.001)\n",
    "criterion = BCEWithLogitsLoss()\n",
    "train(model, train_batches, test_batches, optimizer,  criterion, epochs=20, init_patience=10, cuda=False)\n",
    "model = load_model(model)\n",
    "classification_report(model, test_batches, T_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Last State GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:06<00:00, 16.68it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:06, 15.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, auc: 70.647  Time: 0 minutes, 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:07<00:00, 14.31it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:08, 12.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, auc: 76.110  Time: 0 minutes, 7 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 18.62it/s]\n",
      "  0%|          | 0/107 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, auc: 78.242  Time: 0 minutes, 6 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:06<00:00, 17.73it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:08, 12.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, auc: 79.463  Time: 0 minutes, 6 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 18.18it/s]\n",
      "  3%|▎         | 3/107 [00:00<00:04, 25.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, auc: 80.307  Time: 0 minutes, 6 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 21.23it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:06, 17.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, auc: 80.200  Time: 0 minutes, 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 19.21it/s]\n",
      "  3%|▎         | 3/107 [00:00<00:05, 18.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, auc: 79.781  Time: 0 minutes, 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:06<00:00, 16.40it/s]\n",
      "  4%|▎         | 4/107 [00:00<00:04, 25.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, auc: 79.870  Time: 0 minutes, 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:06<00:00, 17.22it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:08, 12.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, auc: 79.525  Time: 0 minutes, 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:06<00:00, 15.61it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:05, 18.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, auc: 79.638  Time: 0 minutes, 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:07<00:00, 14.79it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:06, 15.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, auc: 78.932  Time: 0 minutes, 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:07<00:00, 14.88it/s]\n",
      "  3%|▎         | 3/107 [00:00<00:04, 22.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, auc: 78.221  Time: 0 minutes, 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:06<00:00, 15.92it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:06, 16.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, auc: 77.728  Time: 0 minutes, 7 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 20.15it/s]\n",
      "  3%|▎         | 3/107 [00:00<00:05, 20.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, auc: 77.632  Time: 0 minutes, 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 21.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, auc: 76.991  Time: 0 minutes, 5 seconds\n",
      "\tEmotion\tAUC\tAccuracy \n",
      "\tanger\t0.8391\t0.7777\n",
      "\tantic\t0.6582\t0.8600\n",
      "\tdisgu\t0.8431\t0.7698\n",
      "\tfear\t0.8488\t0.9007\n",
      "\tjoy\t0.8607\t0.7743\n",
      "\tlove\t0.8848\t0.8837\n",
      "\toptim\t0.8227\t0.7754\n",
      "\tpessi\t0.7483\t0.8871\n",
      "\tsadne\t0.7853\t0.7810\n",
      "\tsurpr\t0.8136\t0.9605\n",
      "\ttrust\t0.7290\t0.9515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.70      0.64      0.67       315\n",
      "anticipation       0.50      0.01      0.02       124\n",
      "     disgust       0.68      0.67      0.68       319\n",
      "        fear       0.76      0.40      0.52       121\n",
      "         joy       0.80      0.67      0.73       400\n",
      "        love       0.74      0.34      0.47       132\n",
      "    optimism       0.74      0.55      0.63       307\n",
      "   pessimism       0.50      0.04      0.07       100\n",
      "     sadness       0.78      0.37      0.51       265\n",
      "    surprise       0.00      0.00      0.00        35\n",
      "       trust       0.00      0.00      0.00        43\n",
      "\n",
      "   micro avg       0.74      0.49      0.59      2161\n",
      "   macro avg       0.56      0.34      0.39      2161\n",
      "weighted avg       0.69      0.49      0.55      2161\n",
      " samples avg       0.63      0.50      0.53      2161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LastStateRNN(emb_matrix)\n",
    "optimizer = Adam(model.params, 0.001)\n",
    "criterion = BCEWithLogitsLoss()\n",
    "train(model, train_batches, test_batches, optimizer,  criterion, epochs=20, init_patience=10, cuda=False)\n",
    "model = load_model(model)\n",
    "classification_report(model, test_batches, T_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Attention GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 19.76it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:05, 19.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, auc: 71.882  Time: 0 minutes, 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 19.48it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:06, 16.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, auc: 75.490  Time: 0 minutes, 5 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 18.08it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:06, 16.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, auc: 77.307  Time: 0 minutes, 6 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 20.97it/s]\n",
      "  3%|▎         | 3/107 [00:00<00:04, 21.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, auc: 78.525  Time: 0 minutes, 5 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:06<00:00, 17.27it/s]\n",
      "  0%|          | 0/107 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, auc: 78.582  Time: 0 minutes, 6 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 20.22it/s]\n",
      "  3%|▎         | 3/107 [00:00<00:04, 24.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, auc: 78.120  Time: 0 minutes, 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 19.23it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:05, 18.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, auc: 78.544  Time: 0 minutes, 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:04<00:00, 22.03it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:06, 15.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, auc: 78.216  Time: 0 minutes, 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 19.31it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:05, 18.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, auc: 78.092  Time: 0 minutes, 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:04<00:00, 21.90it/s]\n",
      "  3%|▎         | 3/107 [00:00<00:05, 19.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, auc: 78.141  Time: 0 minutes, 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 19.49it/s]\n",
      "  3%|▎         | 3/107 [00:00<00:04, 24.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, auc: 77.999  Time: 0 minutes, 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 18.23it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:06, 17.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, auc: 77.562  Time: 0 minutes, 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 18.05it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:06, 15.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, auc: 77.784  Time: 0 minutes, 6 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 21.03it/s]\n",
      "  3%|▎         | 3/107 [00:00<00:03, 26.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, auc: 77.856  Time: 0 minutes, 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:04<00:00, 22.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, auc: 77.839  Time: 0 minutes, 5 seconds\n",
      "\tEmotion\tAUC\tAccuracy \n",
      "\tanger\t0.8337\t0.7788\n",
      "\tantic\t0.6377\t0.8600\n",
      "\tdisgu\t0.8246\t0.7506\n",
      "\tfear\t0.8187\t0.8928\n",
      "\tjoy\t0.8542\t0.7709\n",
      "\tlove\t0.8632\t0.8849\n",
      "\toptim\t0.8124\t0.7585\n",
      "\tpessi\t0.7235\t0.8871\n",
      "\tsadne\t0.7573\t0.7449\n",
      "\tsurpr\t0.7936\t0.9605\n",
      "\ttrust\t0.7250\t0.9515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.73      0.61      0.66       315\n",
      "anticipation       0.00      0.00      0.00       124\n",
      "     disgust       0.66      0.62      0.64       319\n",
      "        fear       0.69      0.40      0.50       121\n",
      "         joy       0.84      0.61      0.71       400\n",
      "        love       0.73      0.36      0.48       132\n",
      "    optimism       0.71      0.51      0.59       307\n",
      "   pessimism       0.50      0.08      0.14       100\n",
      "     sadness       0.61      0.42      0.50       265\n",
      "    surprise       0.00      0.00      0.00        35\n",
      "       trust       0.00      0.00      0.00        43\n",
      "\n",
      "   micro avg       0.71      0.47      0.56      2161\n",
      "   macro avg       0.50      0.33      0.38      2161\n",
      "weighted avg       0.64      0.47      0.53      2161\n",
      " samples avg       0.59      0.48      0.50      2161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SingleAttentionRNN(emb_matrix)\n",
    "optimizer = Adam(model.params, 0.001)\n",
    "criterion = BCEWithLogitsLoss()\n",
    "train(model, train_batches, test_batches, optimizer,  criterion, epochs=20, init_patience=10, cuda=False)\n",
    "model = load_model(model)\n",
    "classification_report(model, test_batches, T_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Attention per Target on GRU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:30<00:00,  3.54it/s]\n",
      "  0%|          | 0/107 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, auc: 73.741  Time: 0 minutes, 31 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:28<00:00,  3.71it/s]\n",
      "  1%|          | 1/107 [00:00<00:15,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, auc: 77.959  Time: 0 minutes, 29 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:35<00:00,  2.97it/s]\n",
      "  1%|          | 1/107 [00:00<00:12,  8.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, auc: 79.337  Time: 0 minutes, 37 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:29<00:00,  3.57it/s]\n",
      "  0%|          | 0/107 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, auc: 79.250  Time: 0 minutes, 31 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:30<00:00,  3.46it/s]\n",
      "  0%|          | 0/107 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, auc: 79.346  Time: 0 minutes, 32 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:29<00:00,  3.64it/s]\n",
      "  1%|          | 1/107 [00:00<00:11,  8.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, auc: 78.787  Time: 0 minutes, 30 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:33<00:00,  3.19it/s]\n",
      "  0%|          | 0/107 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, auc: 78.663  Time: 0 minutes, 34 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:32<00:00,  3.34it/s]\n",
      "  1%|          | 1/107 [00:00<00:15,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, auc: 78.296  Time: 0 minutes, 33 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:28<00:00,  3.69it/s]\n",
      "  1%|          | 1/107 [00:00<00:12,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, auc: 77.440  Time: 0 minutes, 30 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:28<00:00,  3.79it/s]\n",
      "  1%|          | 1/107 [00:00<00:16,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, auc: 76.821  Time: 0 minutes, 29 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:27<00:00,  3.90it/s]\n",
      "  1%|          | 1/107 [00:00<00:17,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, auc: 76.714  Time: 0 minutes, 28 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:27<00:00,  3.87it/s]\n",
      "  0%|          | 0/107 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, auc: 76.630  Time: 0 minutes, 28 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:27<00:00,  3.84it/s]\n",
      "  0%|          | 0/107 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, auc: 76.143  Time: 0 minutes, 28 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:26<00:00,  4.01it/s]\n",
      "  0%|          | 0/107 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14, auc: 75.862  Time: 0 minutes, 27 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:32<00:00,  3.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15, auc: 75.988  Time: 0 minutes, 33 seconds\n",
      "\tEmotion\tAUC\tAccuracy \n",
      "\tanger\t0.8323\t0.7664\n",
      "\tantic\t0.6335\t0.8612\n",
      "\tdisgu\t0.8271\t0.7517\n",
      "\tfear\t0.8584\t0.8962\n",
      "\tjoy\t0.8657\t0.7912\n",
      "\tlove\t0.8825\t0.8905\n",
      "\toptim\t0.8207\t0.7799\n",
      "\tpessi\t0.7222\t0.8860\n",
      "\tsadne\t0.7889\t0.7754\n",
      "\tsurpr\t0.7779\t0.9616\n",
      "\ttrust\t0.7189\t0.9503\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.66      0.70      0.68       315\n",
      "anticipation       0.67      0.02      0.03       124\n",
      "     disgust       0.64      0.71      0.67       319\n",
      "        fear       0.64      0.54      0.59       121\n",
      "         joy       0.85      0.65      0.74       400\n",
      "        love       0.69      0.48      0.57       132\n",
      "    optimism       0.70      0.64      0.67       307\n",
      "   pessimism       0.44      0.04      0.07       100\n",
      "     sadness       0.69      0.45      0.54       265\n",
      "    surprise       1.00      0.03      0.06        35\n",
      "       trust       0.00      0.00      0.00        43\n",
      "\n",
      "   micro avg       0.70      0.54      0.61      2161\n",
      "   macro avg       0.64      0.39      0.42      2161\n",
      "weighted avg       0.69      0.54      0.57      2161\n",
      " samples avg       0.62      0.55      0.56      2161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MultiAttentionRNN(emb_matrix)\n",
    "optimizer = Adam(model.params, 0.001)\n",
    "criterion = BCEWithLogitsLoss()\n",
    "train(model, train_batches, test_batches, optimizer,  criterion, epochs=20, init_patience=10, cuda=False)\n",
    "model = load_model(model)\n",
    "classification_report(model, test_batches, T_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN   of 2-5 kernel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:04<00:00, 25.76it/s]\n",
      "  4%|▎         | 4/107 [00:00<00:03, 29.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, auc: 73.017  Time: 0 minutes, 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:04<00:00, 23.53it/s]\n",
      "  3%|▎         | 3/107 [00:00<00:04, 24.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, auc: 77.310  Time: 0 minutes, 4 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:04<00:00, 21.63it/s]\n",
      "  3%|▎         | 3/107 [00:00<00:03, 28.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, auc: 78.022  Time: 0 minutes, 5 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:03<00:00, 28.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, auc: 77.810  Time: 0 minutes, 3 seconds\n",
      "\tEmotion\tAUC\tAccuracy \n",
      "\tanger\t0.8331\t0.7506\n",
      "\tantic\t0.6364\t0.8600\n",
      "\tdisgu\t0.8283\t0.7472\n",
      "\tfear\t0.8259\t0.8883\n",
      "\tjoy\t0.8555\t0.7686\n",
      "\tlove\t0.8651\t0.8950\n",
      "\toptim\t0.8129\t0.7765\n",
      "\tpessi\t0.7140\t0.8849\n",
      "\tsadne\t0.7624\t0.7630\n",
      "\tsurpr\t0.7499\t0.9605\n",
      "\ttrust\t0.6989\t0.9515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.63      0.72      0.67       315\n",
      "anticipation       0.00      0.00      0.00       124\n",
      "     disgust       0.64      0.68      0.66       319\n",
      "        fear       0.66      0.37      0.48       121\n",
      "         joy       0.85      0.59      0.70       400\n",
      "        love       0.81      0.39      0.52       132\n",
      "    optimism       0.77      0.50      0.61       307\n",
      "   pessimism       0.43      0.06      0.11       100\n",
      "     sadness       0.65      0.45      0.53       265\n",
      "    surprise       0.00      0.00      0.00        35\n",
      "       trust       0.00      0.00      0.00        43\n",
      "\n",
      "   micro avg       0.70      0.49      0.58      2161\n",
      "   macro avg       0.49      0.34      0.39      2161\n",
      "weighted avg       0.64      0.49      0.54      2161\n",
      " samples avg       0.61      0.50      0.52      2161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = CNN(emb_matrix)\n",
    "optimizer = Adam(model.params, 0.001)\n",
    "criterion = BCEWithLogitsLoss()\n",
    "train(model, train_batches, test_batches, optimizer,  criterion, epochs=5, init_patience=1, cuda=False)\n",
    "model = load_model(model)\n",
    "classification_report(model, test_batches, T_LIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concat RNN  - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:18<00:00,  5.80it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:07, 13.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, auc: 74.708  Time: 0 minutes, 19 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:16<00:00,  6.48it/s]\n",
      "  1%|          | 1/107 [00:00<00:13,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, auc: 78.062  Time: 0 minutes, 17 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.22it/s]\n",
      "  0%|          | 0/107 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, auc: 78.184  Time: 0 minutes, 17 seconds\n",
      "best epoch so far\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:15<00:00,  6.87it/s]\n",
      "  1%|          | 1/107 [00:00<00:18,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, auc: 77.975  Time: 0 minutes, 16 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:14<00:00,  7.17it/s]\n",
      "  1%|          | 1/107 [00:00<00:18,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, auc: 77.393  Time: 0 minutes, 15 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:15<00:00,  6.93it/s]\n",
      "  1%|          | 1/107 [00:00<00:11,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, auc: 76.957  Time: 0 minutes, 16 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:16<00:00,  6.55it/s]\n",
      "  1%|          | 1/107 [00:00<00:16,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, auc: 76.329  Time: 0 minutes, 16 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:15<00:00,  6.72it/s]\n",
      "  1%|          | 1/107 [00:00<00:12,  8.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, auc: 75.727  Time: 0 minutes, 16 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:13<00:00,  7.73it/s]\n",
      "  2%|▏         | 2/107 [00:00<00:09, 10.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, auc: 75.845  Time: 0 minutes, 14 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.21it/s]\n",
      "  1%|          | 1/107 [00:00<00:16,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10, auc: 75.114  Time: 0 minutes, 17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:16<00:00,  6.38it/s]\n",
      "  1%|          | 1/107 [00:00<00:12,  8.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11, auc: 75.019  Time: 0 minutes, 17 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:15<00:00,  6.71it/s]\n",
      "  1%|          | 1/107 [00:00<00:12,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12, auc: 74.575  Time: 0 minutes, 16 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:17<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13, auc: 75.089  Time: 0 minutes, 18 seconds\n",
      "\tEmotion\tAUC\tAccuracy \n",
      "\tanger\t0.8284\t0.7675\n",
      "\tantic\t0.6372\t0.8589\n",
      "\tdisgu\t0.8247\t0.7472\n",
      "\tfear\t0.8369\t0.8984\n",
      "\tjoy\t0.8597\t0.7765\n",
      "\tlove\t0.8819\t0.8837\n",
      "\toptim\t0.8127\t0.7675\n",
      "\tpessi\t0.7282\t0.8849\n",
      "\tsadne\t0.7629\t0.7630\n",
      "\tsurpr\t0.7399\t0.9605\n",
      "\ttrust\t0.6876\t0.9515\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.68      0.64      0.66       315\n",
      "anticipation       0.00      0.00      0.00       124\n",
      "     disgust       0.64      0.68      0.66       319\n",
      "        fear       0.72      0.41      0.53       121\n",
      "         joy       0.86      0.60      0.71       400\n",
      "        love       0.63      0.52      0.57       132\n",
      "    optimism       0.78      0.46      0.58       307\n",
      "   pessimism       0.45      0.10      0.16       100\n",
      "     sadness       0.64      0.47      0.54       265\n",
      "    surprise       0.00      0.00      0.00        35\n",
      "       trust       0.00      0.00      0.00        43\n",
      "\n",
      "   micro avg       0.71      0.49      0.58      2161\n",
      "   macro avg       0.49      0.35      0.40      2161\n",
      "weighted avg       0.64      0.49      0.55      2161\n",
      " samples avg       0.59      0.50      0.51      2161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = MultiAttentionRNNConcatCNN(emb_matrix)\n",
    "optimizer = Adam(model.params, 0.001)\n",
    "criterion = BCEWithLogitsLoss()\n",
    "train(model, train_batches, test_batches, optimizer,  criterion, epochs=20, init_patience=10, cuda=False)\n",
    "model = load_model(model)\n",
    "classification_report(model, test_batches, T_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
